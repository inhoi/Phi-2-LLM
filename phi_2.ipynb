{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f88bc686cca849fdbe2aeea655fa91cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00ae8aa8930146c18052fb456064f5b2",
              "IPY_MODEL_6b6dfdc8a9a44906a4f09503f5fb0ef0",
              "IPY_MODEL_03e5a738d160412980c94b47d7a1fd99"
            ],
            "layout": "IPY_MODEL_2d8c63919625400483582a3afdd9b9c1"
          }
        },
        "00ae8aa8930146c18052fb456064f5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ab6d13b561648539f85b3e8d4d41f01",
            "placeholder": "​",
            "style": "IPY_MODEL_406baa187f644f0b9d834bb122557068",
            "value": "Generating train split: "
          }
        },
        "6b6dfdc8a9a44906a4f09503f5fb0ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29bff93c5574244ac3a91b88b81ec47",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0eb1310887c843848c25acabae7dca09",
            "value": 1
          }
        },
        "03e5a738d160412980c94b47d7a1fd99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14e20552dbda4689b9e26a61d5ea90bc",
            "placeholder": "​",
            "style": "IPY_MODEL_0506a01156cf4f40878c3e61a9d8ce18",
            "value": " 137/0 [00:00&lt;00:00,  6.37 examples/s]"
          }
        },
        "2d8c63919625400483582a3afdd9b9c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab6d13b561648539f85b3e8d4d41f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "406baa187f644f0b9d834bb122557068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b29bff93c5574244ac3a91b88b81ec47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0eb1310887c843848c25acabae7dca09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14e20552dbda4689b9e26a61d5ea90bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0506a01156cf4f40878c3e61a9d8ce18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c040104a295646918ec842304d89010f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ba13eac66d948c9b21d7a8f2bc93617",
              "IPY_MODEL_4671f65330334b7f805def6b3d97c4ff",
              "IPY_MODEL_e9f8ceee969949c09e2418ae7b708f54"
            ],
            "layout": "IPY_MODEL_5abde14cb48b41cabcb39dfd584d834e"
          }
        },
        "1ba13eac66d948c9b21d7a8f2bc93617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06ddf26bdfd34796b799850e53c706a8",
            "placeholder": "​",
            "style": "IPY_MODEL_e53f70f1c09e4d61b17a18aeff674f10",
            "value": "Generating train split: "
          }
        },
        "4671f65330334b7f805def6b3d97c4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_455d15a0092c4c5da9906c22f360b071",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9094977cc66d4f1786338f476009d57d",
            "value": 1
          }
        },
        "e9f8ceee969949c09e2418ae7b708f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c405f66bd55944f8bdb9e266f61adb2a",
            "placeholder": "​",
            "style": "IPY_MODEL_f1e16415c55b4ce6b3d4b7337ff60ed8",
            "value": " 33/0 [00:00&lt;00:00, 419.67 examples/s]"
          }
        },
        "5abde14cb48b41cabcb39dfd584d834e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ddf26bdfd34796b799850e53c706a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e53f70f1c09e4d61b17a18aeff674f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "455d15a0092c4c5da9906c22f360b071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9094977cc66d4f1786338f476009d57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c405f66bd55944f8bdb9e266f61adb2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1e16415c55b4ce6b3d4b7337ff60ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.2.1\n",
        "!pip install accelerate\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install --upgrade -q -U transformers\n",
        "!pip install -q -U xformers\n",
        "!pip install -q -U peft\n",
        "!pip install -q -U datasets\n",
        "!pip install -q -U trl\n",
        "!pip install -q -U einops"
      ],
      "metadata": {
        "id": "iKZFKR6cTSU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLq0dvvjb-1B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import transformers\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    AutoModelWithLMHead,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/TalkFile_ner_2.csv').iloc[:1000,:]\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "df = df[['Sentence']]\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "i3Jp5AQMcLQd",
        "outputId": "2ff071eb-09bb-494f-d65f-407d490ecb93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                               Sentence\n",
              "0                     Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
              "1  Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \"\n",
              "2                                                                                                  They marched from the Houses of Parliament to a rally in Hyde Park .\n",
              "3                                                                                Police put the number of marchers at 10,000 while organizers claimed it was 1,00,000 .\n",
              "4                           The protest comes on the eve of the annual conference of Britain 's ruling Labor Party in the southern English seaside resort of Brighton .\n",
              "5                        The party is divided over Britain 's participation in the Iraq conflict and the continued deployment of 8,500 British troops in that country .\n",
              "6                                                        The London march came ahead of anti-war protests today in other cities , including Rome , Paris , and Madrid .\n",
              "7   The International Atomic Energy Agency is to hold second day of talks in Vienna Wednesday on how to respond to Iran 's resumption of low-level uranium conversion .\n",
              "8                                                                               Iran this week restarted parts of the conversion process at its Isfahan nuclear plant .\n",
              "9             Iranian officials say they expect to get access to sealed sensitive parts of the plant Wednesday , after an IAEA surveillance system begins functioning ."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8042f225-dfe7-426c-abc9-1ed1d216d83e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They marched from the Houses of Parliament to a rally in Hyde Park .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Police put the number of marchers at 10,000 while organizers claimed it was 1,00,000 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The protest comes on the eve of the annual conference of Britain 's ruling Labor Party in the southern English seaside resort of Brighton .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The party is divided over Britain 's participation in the Iraq conflict and the continued deployment of 8,500 British troops in that country .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The London march came ahead of anti-war protests today in other cities , including Rome , Paris , and Madrid .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The International Atomic Energy Agency is to hold second day of talks in Vienna Wednesday on how to respond to Iran 's resumption of low-level uranium conversion .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Iran this week restarted parts of the conversion process at its Isfahan nuclear plant .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Iranian officials say they expect to get access to sealed sensitive parts of the plant Wednesday , after an IAEA surveillance system begins functioning .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8042f225-dfe7-426c-abc9-1ed1d216d83e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8042f225-dfe7-426c-abc9-1ed1d216d83e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8042f225-dfe7-426c-abc9-1ed1d216d83e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ca140cd1-7eaf-446d-974b-7f146c2aa687\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca140cd1-7eaf-446d-974b-7f146c2aa687')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ca140cd1-7eaf-446d-974b-7f146c2aa687 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Statements Wednesday say the suspects were detained in separate operations north of Baghdad in Kirkuk province , and in the towns of Tarmiyah and Judaidah .\",\n          \"More than $ 1 billion came from the United States and the large Haitian communities in Boston , Miami , and New~York .\",\n          \"They use the extra funds for basic expenses , while others invest it in small businesses and education for their children .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "for i in df['Sentence']:\n",
        "  max_len = max(max_len, len(i))\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-sR2MSDjENQ",
        "outputId": "8ecb6534-ea39-4abd-dacc-b9ed3bf4a4cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_ques = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n",
        "model_ques = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n",
        "\n",
        "def get_question(context, max_length=100):\n",
        "  input_text = \"context: %s </s>\" % (context)\n",
        "  features = tokenizer_ques([input_text], return_tensors='pt')\n",
        "\n",
        "  output = model_ques.generate(input_ids=features['input_ids'],\n",
        "               attention_mask=features['attention_mask'],\n",
        "               max_length=max_length)\n",
        "\n",
        "  return tokenizer_ques.decode(output[0])"
      ],
      "metadata": {
        "id": "Qo3hysIhFLMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [get_question(sentence) for sentence in df['Sentence']]\n",
        "questions[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVZ27XCvICwJ",
        "outputId": "a2f8f68e-08cd-447f-fb4f-f209b7ef5ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad> question: What is the name of the protests in London?</s>',\n",
              " '<pad> question: What was the name of the protesters?</s>',\n",
              " '<pad> question: What was the name of the rally?</s>',\n",
              " '<pad> question: How many marchers were there?</s>',\n",
              " '<pad> question: What is the name of the protest in Brighton?</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_question(question):\n",
        "    question = question.replace('<pad> question:', '').replace('</s>', '').strip()\n",
        "    return question\n",
        "\n",
        "questions_cleaned = [clean_question(get_question(sentence)) for sentence in df['Sentence']]\n",
        "df_questions = pd.DataFrame({'Sentence': df['Sentence'], 'Question': questions_cleaned})\n",
        "\n",
        "def format_dataset(dataframe):\n",
        "    dataframe['Formatted'] = dataframe.apply(lambda row: f\"### Instruction: {row['Question']} ### Assistant: {row['Sentence']}\", axis=1)\n",
        "    return dataframe\n",
        "\n",
        "formatted_df = format_dataset(df_questions)\n",
        "\n",
        "new_df = formatted_df[['Formatted']]\n",
        "new_df.to_csv('formatted_df.csv', index=False)\n",
        "new_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "KwGgq-cyLZU3",
        "outputId": "649ade91-cc4d-432c-ffe0-279f3c7440f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                   Formatted\n",
              "0              ### Instruction: What is the name of the protests in London? ### Assistant: Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
              "1  ### Instruction: What was the name of the protesters? ### Assistant: Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \"\n",
              "2                                                                                                       ### Instruction: What was the name of the rally? ### Assistant: They marched from the Houses of Parliament to a rally in Hyde Park .\n",
              "3                                                                                       ### Instruction: How many marchers were there? ### Assistant: Police put the number of marchers at 10,000 while organizers claimed it was 1,00,000 .\n",
              "4                   ### Instruction: What is the name of the protest in Brighton? ### Assistant: The protest comes on the eve of the annual conference of Britain 's ruling Labor Party in the southern English seaside resort of Brighton ."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-994dae58-c370-4002-b39e-369bdc2b378e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Formatted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>### Instruction: What is the name of the protests in London? ### Assistant: Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>### Instruction: What was the name of the protesters? ### Assistant: Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>### Instruction: What was the name of the rally? ### Assistant: They marched from the Houses of Parliament to a rally in Hyde Park .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>### Instruction: How many marchers were there? ### Assistant: Police put the number of marchers at 10,000 while organizers claimed it was 1,00,000 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>### Instruction: What is the name of the protest in Brighton? ### Assistant: The protest comes on the eve of the annual conference of Britain 's ruling Labor Party in the southern English seaside resort of Brighton .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-994dae58-c370-4002-b39e-369bdc2b378e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-994dae58-c370-4002-b39e-369bdc2b378e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-994dae58-c370-4002-b39e-369bdc2b378e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5acf402b-7ac1-4fd0-b60d-aa0f4e877d34\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5acf402b-7ac1-4fd0-b60d-aa0f4e877d34')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5acf402b-7ac1-4fd0-b60d-aa0f4e877d34 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "new_df",
              "summary": "{\n  \"name\": \"new_df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Formatted\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"### Instruction: What is the name of the two towns where the suspects were detained? ### Assistant: Statements Wednesday say the suspects were detained in separate operations north of Baghdad in Kirkuk province , and in the towns of Tarmiyah and Judaidah .\",\n          \"### Instruction: How much money did Haitian communities receive? ### Assistant: More than $ 1 billion came from the United States and the large Haitian communities in Boston , Miami , and New~York .\",\n          \"### Instruction: What do parents use the extra funds for? ### Assistant: They use the extra funds for basic expenses , while others invest it in small businesses and education for their children .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base model"
      ],
      "metadata": {
        "id": "zYd1b6cXWfwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_id = \"microsoft/phi-2\"\n",
        "\n",
        "#Load the tokenizer\n",
        "tokenizer_fp16 = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n",
        "#Load the model with fp16\n",
        "model_fp16 =  AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True, torch_dtype=torch.float16, device_map={\"\": 0})"
      ],
      "metadata": {
        "id": "8ARp0hDZSwYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "duration = 0.0\n",
        "total_length = 0\n",
        "prompt = []\n",
        "prompt.append(\"Who is the president of Iran mentioned in the news?\")\n",
        "prompt.append(\"Provide details on the mortar shell attack in Somalia.\")\n",
        "prompt.append('Describe the incident involving Germans in Nigeria.')\n",
        "prompt.append(\"What actions have the militants taken in the Niger Delta?\")\n",
        "\n",
        "for i in range(len(prompt)):\n",
        "  model_inputs = tokenizer_fp16(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n",
        "  start_time = time.time()\n",
        "  output = model_fp16.generate(**model_inputs, max_length=150)[0]\n",
        "  duration += float(time.time() - start_time)\n",
        "  total_length += len(output)\n",
        "  tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n",
        "  print(\"Prompt --- %s tokens/seconds ---\" % (tok_sec_prompt))\n",
        "  print(tokenizer_fp16.decode(output, skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-houp8kS1K6",
        "outputId": "0a827b88-4bab-4bcb-cee5-f52ec3c2a511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt --- 26.837 tokens/seconds ---\n",
            "Who is the president of Iran mentioned in the news?\n",
            "Answer: Hassan Rouhani.\n",
            "\n",
            "Exercise 2:\n",
            "What is the name of the new law that was passed in Iran?\n",
            "Answer: The new law is called the \"Law on the Protection of the Rights of the Child.\"\n",
            "\n",
            "Exercise 3:\n",
            "How does the new law protect children in Iran?\n",
            "Answer: The new law protects children by making sure they have access to education, healthcare, and a safe environment.\n",
            "\n",
            "Exercise 4:\n",
            "Why is it important for children to have access to education?\n",
            "Answer: It is important for children to have access to education because it helps them learn and grow, and prepares them for their future.\n",
            "\n",
            "Ex\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt --- 24.474 tokens/seconds ---\n",
            "Provide details on the mortar shell attack in Somalia.\n",
            "Answer: The mortar shell attack in Somalia was a targeted attack on a convoy of United Nations peacekeepers, resulting in the deaths of two peacekeepers and injuries to several others. The attack was carried out by a group of armed men who used a mortar to fire at the convoy. The attack was condemned by the United Nations and the Somali government, and the perpetrators were later identified and arrested.\n",
            "\n",
            "Exercise: What was the purpose of the United Nations Security Council Resolution 1373?\n",
            "Answer: The purpose of the United Nations Security Council Resolution 1373 was to address the threat of terrorism and to take action against those who support or carry out terrorist acts. It also aimed to promote international\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt --- 27.03 tokens/seconds ---\n",
            "Describe the incident involving Germans in Nigeria.\n",
            "Answer: In the late 1960s, a group of Germans were involved in a violent incident in Nigeria, resulting in the death of a Nigerian man. This incident caused tension between the two countries and led to the expulsion of the German ambassador.\n",
            "\n",
            "Exercise: What was the purpose of the German embassy in Abuja?\n",
            "Answer: The German embassy in Abuja serves as the diplomatic mission of Germany in Nigeria, representing the interests of the German government and promoting cultural and economic ties between the two countries.\n",
            "\n",
            "Exercise: How did the incident involving Germans in Nigeria impact the relationship between the two countries?\n",
            "Answer: The incident caused tension and strained the relationship between Germany and Nigeria, leading\n",
            "Prompt --- 24.965 tokens/seconds ---\n",
            "What actions have the militants taken in the Niger Delta?\n",
            "Answer: The militants have attacked oil installations, kidnapped oil workers, and caused disruptions in oil production.\n",
            "\n",
            "Exercise: What is the main goal of the militants?\n",
            "Answer: The main goal of the militants is to gain control of the oil resources in the Niger Delta and use the money for their own benefit.\n",
            "\n",
            "Exercise: How have the Nigerian government and oil companies responded to the attacks?\n",
            "Answer: The Nigerian government and oil companies have increased security measures and have launched military operations to combat the militants.\n",
            "\n",
            "Exercise: What is the impact of the attacks on the Nigerian economy?\n",
            "Answer: The attacks have caused disruptions in oil production and have led to a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantized model"
      ],
      "metadata": {
        "id": "I14VnYDGfqxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_id = \"microsoft/phi-2\"\n",
        "\n",
        "tokenizer_np4 = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n",
        "\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "model_np4 = AutoModelForCausalLM.from_pretrained(\n",
        "          base_model_id, trust_remote_code=True, quantization_config=bnb_config, device_map={\"\": 0}, torch_dtype=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "ofv1lpSyUi0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "duration = 0.0\n",
        "total_length = 0\n",
        "prompt = []\n",
        "prompt.append(\"Who is the president of Iran mentioned in the news?\")\n",
        "prompt.append(\"Provide details on the mortar shell attack in Somalia.\")\n",
        "prompt.append('Describe the incident involving Germans in Nigeria.')\n",
        "prompt.append(\"What actions have the militants taken in the Niger Delta?\")\n",
        "\n",
        "for i in range(len(prompt)):\n",
        "  model_inputs = tokenizer_np4(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n",
        "  start_time = time.time()\n",
        "  output = model_np4.generate(**model_inputs, max_length=150)[0]\n",
        "  duration += float(time.time() - start_time)\n",
        "  total_length += len(output)\n",
        "  tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n",
        "  print(\"Prompt --- %s tokens/seconds ---\" % (tok_sec_prompt))\n",
        "  print(tokenizer_np4.decode(output, skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVMPnm_jGLc7",
        "outputId": "8d7c081a-0915-468f-c5b2-c52243f30677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt --- 13.536 tokens/seconds ---\n",
            "Who is the president of Iran mentioned in the news?\n",
            "Answer: The president of Iran mentioned in the news is Hassan Rouhani.\n",
            "\n",
            "Exercise 2:\n",
            "What is the name of the new law that was passed in Iran?\n",
            "Answer: The new law that was passed in Iran is called the \"Law on the Protection of the Rights of the Child.\"\n",
            "\n",
            "Exercise 3:\n",
            "How does the new law in Iran protect children?\n",
            "Answer: The new law in Iran protects children by giving them the right to education, healthcare, and protection from abuse and exploitation.\n",
            "\n",
            "Exercise 4:\n",
            "Why is it important for children to have the right to education?\n",
            "Answer: It is important for children to have the right to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt --- 13.796 tokens/seconds ---\n",
            "Provide details on the mortar shell attack in Somalia.\n",
            "Answer: The mortar shell attack in Somalia was carried out by the Islamic Courts Union (ICU) on the town of Baidoa. The attack was carried out by a mortar unit of the ICU, which targeted the town's main market. The attack resulted in the death of at least 20 people and injured over 100 others. The ICU claimed responsibility for the attack, stating that it was in retaliation for the ongoing conflict in the region.\n",
            "\n",
            "Exercise: What was the purpose of the attack on the town of Baidoa?\n",
            "Answer: The purpose of the attack on the town of Baidoa was to retaliate against the ongoing conflict in the region and to weaken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt --- 13.971 tokens/seconds ---\n",
            "Describe the incident involving Germans in Nigeria.\n",
            "Answer: In the late 1960s, a group of Germans were involved in a violent incident in Nigeria. They were accused of killing a Nigerian man and were later found guilty and sentenced to death. This incident caused tension between the two countries and led to the expulsion of the German ambassador.\n",
            "\n",
            "Exercise: What was the purpose of the German embassy in Nigeria?\n",
            "Answer: The German embassy in Nigeria served as a diplomatic mission to represent the interests of Germany in Nigeria.\n",
            "\n",
            "Exercise: How did the incident involving Germans in Nigeria impact the relationship between the two countries?\n",
            "Answer: The incident caused tension and strained the relationship between Germany and Nigeria. It also led to the expulsion of the\n",
            "Prompt --- 14.524 tokens/seconds ---\n",
            "What actions have the militants taken in the Niger Delta?\n",
            "Answer: The militants have attacked oil installations, causing disruptions in oil production and resulting in significant financial losses for the Nigerian government.\n",
            "\n",
            "Exercise: What is the main goal of the militants?\n",
            "Answer: The main goal of the militants is to gain control of the Niger Delta region and its resources.\n",
            "\n",
            "Exercise: How have the Nigerian government and the militants been involved in the conflict?\n",
            "Answer: The Nigerian government has been trying to suppress the militants, while the militants have been fighting for their rights and resources.\n",
            "\n",
            "Exercise: What is the impact of the conflict on the Nigerian economy?\n",
            "Answer: The conflict has resulted in significant financial losses for the Nigerian government\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tune"
      ],
      "metadata": {
        "id": "NHpuIS48MJ4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_id = \"microsoft/phi-2\"\n",
        "\n",
        "tokenizer_fine = AutoTokenizer.from_pretrained(base_model_id, add_eos_token=True, use_fast=True)\n",
        "tokenizer_fine.padding_side = 'right'\n",
        "tokenizer_fine.pad_token = tokenizer_fine.eos_token\n",
        "\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "model_fine = AutoModelForCausalLM.from_pretrained(\n",
        "          base_model_id, trust_remote_code=True, quantization_config=bnb_config, device_map={\"\": 0}, torch_dtype=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "CvdAcP-wL7jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fine = prepare_model_for_kbit_training(model_fine)\n",
        "print(model_fine)\n",
        "dataset = Dataset.from_pandas(new_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_fZPmbRMW4s",
        "outputId": "e7588d84-8ad8-458e-9bb5-c12aea04dd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PhiForCausalLM(\n",
            "  (model): PhiModel(\n",
            "    (embed_tokens): Embedding(51200, 2560)\n",
            "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x PhiDecoderLayer(\n",
            "        (self_attn): PhiAttention(\n",
            "          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
            "          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
            "          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
            "          (rotary_emb): PhiRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): PhiMLP(\n",
            "          (activation_fn): NewGELUActivation()\n",
            "          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
            "          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
            "        )\n",
            "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        r=16,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        target_modules= [\"q_proj\",\"k_proj\",\"v_proj\",\"fc2\",\"fc1\"]\n",
        ")"
      ],
      "metadata": {
        "id": "j2QMdwzqNbNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "        output_dir=\"./phi2-results2\",\n",
        "        evaluation_strategy=\"steps\",\n",
        "        do_eval=True,\n",
        "        per_device_train_batch_size=4,\n",
        "        gradient_accumulation_steps=6,\n",
        "        per_device_eval_batch_size=1,\n",
        "        log_level=\"debug\",\n",
        "        save_strategy='epoch',\n",
        "        logging_steps=10,\n",
        "        learning_rate=1e-4,\n",
        "        eval_steps=25,\n",
        "        optim='paged_adamw_8bit',\n",
        "        fp16=True,\n",
        "        num_train_epochs=10,\n",
        "        warmup_steps=10,\n",
        "        lr_scheduler_type=\"linear\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMXZLykWNf5-",
        "outputId": "c8af1ab7-281a-4143-bb71-8be569466d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "train_test_split = dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_test_split['train'],\n",
        "    'test': train_test_split['test']\n",
        "})\n",
        "\n",
        "print(dataset_dict['train'].column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVZLkX7_QaBl",
        "outputId": "95cdb261-c9d8-4d65-8142-3bd8139a0c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Formatted']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "        model=model_fine,\n",
        "        train_dataset=dataset_dict['train'],\n",
        "        eval_dataset=dataset_dict['test'],\n",
        "        peft_config=peft_config,\n",
        "        dataset_text_field=\"Formatted\",\n",
        "        max_seq_length=256,\n",
        "        tokenizer=tokenizer_fine,\n",
        "        args=training_arguments,\n",
        "        packing=True\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f88bc686cca849fdbe2aeea655fa91cc",
            "00ae8aa8930146c18052fb456064f5b2",
            "6b6dfdc8a9a44906a4f09503f5fb0ef0",
            "03e5a738d160412980c94b47d7a1fd99",
            "2d8c63919625400483582a3afdd9b9c1",
            "7ab6d13b561648539f85b3e8d4d41f01",
            "406baa187f644f0b9d834bb122557068",
            "b29bff93c5574244ac3a91b88b81ec47",
            "0eb1310887c843848c25acabae7dca09",
            "14e20552dbda4689b9e26a61d5ea90bc",
            "0506a01156cf4f40878c3e61a9d8ce18",
            "c040104a295646918ec842304d89010f",
            "1ba13eac66d948c9b21d7a8f2bc93617",
            "4671f65330334b7f805def6b3d97c4ff",
            "e9f8ceee969949c09e2418ae7b708f54",
            "5abde14cb48b41cabcb39dfd584d834e",
            "06ddf26bdfd34796b799850e53c706a8",
            "e53f70f1c09e4d61b17a18aeff674f10",
            "455d15a0092c4c5da9906c22f360b071",
            "9094977cc66d4f1786338f476009d57d",
            "c405f66bd55944f8bdb9e266f61adb2a",
            "f1e16415c55b4ce6b3d4b7337ff60ed8"
          ]
        },
        "id": "grN38W3kNtyz",
        "outputId": "693bd61c-7cef-4c84-f437-6461a1d3021e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f88bc686cca849fdbe2aeea655fa91cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c040104a295646918ec842304d89010f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "Using auto half precision backend\n",
            "Currently training with a batch size of: 4\n",
            "***** Running training *****\n",
            "  Num examples = 137\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 6\n",
            "  Total optimization steps = 50\n",
            "  Number of trainable parameters = 20,971,520\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 16:04, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.473700</td>\n",
              "      <td>2.162195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.959800</td>\n",
              "      <td>1.979158</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./phi2-results2/checkpoint-5\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-2/snapshots/b10c3eba545ad279e7208ee3a5d644566f001670/config.json\n",
            "Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-2\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"microsoft/phi-2--configuration_phi.PhiConfig\",\n",
            "    \"AutoModelForCausalLM\": \"microsoft/phi-2--modeling_phi.PhiForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2560,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 10240,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.4,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./phi2-results2/checkpoint-5/tokenizer_config.json\n",
            "Special tokens file saved in ./phi2-results2/checkpoint-5/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to ./phi2-results2/checkpoint-11\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-2/snapshots/b10c3eba545ad279e7208ee3a5d644566f001670/config.json\n",
            "Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-2\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"microsoft/phi-2--configuration_phi.PhiConfig\",\n",
            "    \"AutoModelForCausalLM\": \"microsoft/phi-2--modeling_phi.PhiForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2560,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 10240,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.4,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./phi2-results2/checkpoint-11/tokenizer_config.json\n",
            "Special tokens file saved in ./phi2-results2/checkpoint-11/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to ./phi2-results2/checkpoint-17\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-2/snapshots/b10c3eba545ad279e7208ee3a5d644566f001670/config.json\n",
            "Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-2\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"microsoft/phi-2--configuration_phi.PhiConfig\",\n",
            "    \"AutoModelForCausalLM\": \"microsoft/phi-2--modeling_phi.PhiForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2560,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 10240,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.4,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./phi2-results2/checkpoint-17/tokenizer_config.json\n",
            "Special tokens file saved in ./phi2-results2/checkpoint-17/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to ./phi2-results2/checkpoint-23\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-2/snapshots/b10c3eba545ad279e7208ee3a5d644566f001670/config.json\n",
            "Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-2\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"microsoft/phi-2--configuration_phi.PhiConfig\",\n",
            "    \"AutoModelForCausalLM\": \"microsoft/phi-2--modeling_phi.PhiForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2560,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 10240,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.4,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./phi2-results2/checkpoint-23/tokenizer_config.json\n",
            "Special tokens file saved in ./phi2-results2/checkpoint-23/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 33\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to ./phi2-results2/checkpoint-29\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-2/snapshots/b10c3eba545ad279e7208ee3a5d644566f001670/config.json\n",
            "Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-2\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"microsoft/phi-2--configuration_phi.PhiConfig\",\n",
            "    \"AutoModelForCausalLM\": \"microsoft/phi-2--modeling_phi.PhiForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2560,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 10240,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.4,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./phi2-results2/checkpoint-29/tokenizer_config.json\n",
            "Special tokens file saved in ./phi2-results2/checkpoint-29/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to ./phi2-results2/checkpoint-35\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-2/snapshots/b10c3eba545ad279e7208ee3a5d644566f001670/config.json\n",
            "Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-2\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"microsoft/phi-2--configuration_phi.PhiConfig\",\n",
            "    \"AutoModelForCausalLM\": \"microsoft/phi-2--modeling_phi.PhiForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2560,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 10240,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.4,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./phi2-results2/checkpoint-35/tokenizer_config.json\n",
            "Special tokens file saved in ./phi2-results2/checkpoint-35/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to ./phi2-results2/checkpoint-40\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-2/snapshots/b10c3eba545ad279e7208ee3a5d644566f001670/config.json\n",
            "Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-2\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"microsoft/phi-2--configuration_phi.PhiConfig\",\n",
            "    \"AutoModelForCausalLM\": \"microsoft/phi-2--modeling_phi.PhiForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2560,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 10240,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.4,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./phi2-results2/checkpoint-40/tokenizer_config.json\n",
            "Special tokens file saved in ./phi2-results2/checkpoint-40/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to ./phi2-results2/checkpoint-46\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-2/snapshots/b10c3eba545ad279e7208ee3a5d644566f001670/config.json\n",
            "Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-2\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"microsoft/phi-2--configuration_phi.PhiConfig\",\n",
            "    \"AutoModelForCausalLM\": \"microsoft/phi-2--modeling_phi.PhiForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2560,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 10240,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.4,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./phi2-results2/checkpoint-46/tokenizer_config.json\n",
            "Special tokens file saved in ./phi2-results2/checkpoint-46/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 33\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to ./phi2-results2/checkpoint-50\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-2/snapshots/b10c3eba545ad279e7208ee3a5d644566f001670/config.json\n",
            "Model config PhiConfig {\n",
            "  \"_name_or_path\": \"microsoft/phi-2\",\n",
            "  \"architectures\": [\n",
            "    \"PhiForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"microsoft/phi-2--configuration_phi.PhiConfig\",\n",
            "    \"AutoModelForCausalLM\": \"microsoft/phi-2--modeling_phi.PhiForCausalLM\"\n",
            "  },\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_size\": 2560,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 10240,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"phi\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"partial_rotary_factor\": 0.4,\n",
            "  \"qk_layernorm\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./phi2-results2/checkpoint-50/tokenizer_config.json\n",
            "Special tokens file saved in ./phi2-results2/checkpoint-50/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=50, training_loss=2.2933678436279297, metrics={'train_runtime': 982.7392, 'train_samples_per_second': 1.394, 'train_steps_per_second': 0.051, 'total_flos': 4822164528168960.0, 'train_loss': 2.2933678436279297, 'epoch': 8.57})"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tuned adapter"
      ],
      "metadata": {
        "id": "j7jlhfyemree"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_id = \"microsoft/phi-2\"\n",
        "\n",
        "tokenizer_final = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n",
        "\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "model_final = AutoModelForCausalLM.from_pretrained(\n",
        "          base_model_id, trust_remote_code=True, quantization_config=bnb_config, torch_dtype=\"auto\", device_map={\"\": 0}\n",
        ")\n",
        "adapter = \"/content/phi2-results2/checkpoint-50\"\n",
        "model_final = PeftModel.from_pretrained(model_final, adapter)"
      ],
      "metadata": {
        "id": "_-HLBcvtOGXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duration = 0.0\n",
        "total_length = 0\n",
        "prompt = []\n",
        "prompt.append(\"### Human: Write the recipe for a chicken curry with coconut milk.### Assistant:\")\n",
        "prompt.append(\"### Human: Who is the president of Iran mentioned in the news?### Assistant:\")\n",
        "prompt.append(\"### Human: Provide details on the mortar shell attack in Somalia.### Assistant:\")\n",
        "prompt.append(\"### Human: Describe the incident involving Germans in Nigeria.### Assistant:\")\n",
        "prompt.append(\"### Human: What actions have the militants taken in the Niger Delta?### Assistant:\")\n",
        "\n",
        "for i in range(len(prompt)):\n",
        "  model_inputs = tokenizer_final(prompt[i], return_tensors=\"pt\").to(\"cuda:0\")\n",
        "  start_time = time.time()\n",
        "  input_length = model_inputs.input_ids.size(1)\n",
        "  output = model_final.generate(**model_inputs,\n",
        "                                max_length=input_length + 50,\n",
        "                                no_repeat_ngram_size=10,\n",
        "                                pad_token_id=tokenizer_final.eos_token_id,\n",
        "                                eos_token_id=tokenizer_final.eos_token_id,\n",
        "                                early_stopping=True)[0]\n",
        "  duration += float(time.time() - start_time)\n",
        "  total_length += len(output)\n",
        "  tok_sec_prompt = round(len(output)/float(time.time() - start_time),3)\n",
        "  print(\"Prompt --- %s tokens/seconds ---\" % (tok_sec_prompt))\n",
        "  print()\n",
        "  print(tokenizer_final.decode(output, skip_special_tokens=True))\n",
        "  print()\n",
        "\n",
        "tok_sec = round(total_length/duration,3)\n",
        "print(\"Average --- %s tokens/seconds ---\" % (tok_sec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ypiHYE8TnD6",
        "outputId": "49bc476b-d469-4da4-86b2-6f8bc3130884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt --- 6.882 tokens/seconds ---\n",
            "\n",
            "### Human: Write the recipe for a chicken curry with coconut milk.### Assistant: To make chicken curry with coconut milk, you will need chicken, onions, garlic, ginger, tomatoes, and spices. ### Assistant: First, sauté the onions, garlic, and ginger in a large pot. ### Assistant: Then, add\n",
            "\n",
            "Prompt --- 10.485 tokens/seconds ---\n",
            "\n",
            "### Human: Who is the president of Iran mentioned in the news?### Assistant: The news says that the president of Iran is Ali Khamenei. ### Assistant: The news says that the president of Iraq is Jalal Talabani. ### Assistant: The news says that the prime minister of Israel is Ehud Olmert.\n",
            "\n",
            "Prompt --- 10.248 tokens/seconds ---\n",
            "\n",
            "### Human: Provide details on the mortar shell attack in Somalia.### Assistant: A mortar shell attack in Somalia killed at least two people and wounded three others on Friday. ### Human: What is the name of the U.N. peacekeeping force in Somalia? ### Assistant: The U.N. peacekeeping force in Somalia\n",
            "\n",
            "Prompt --- 11.226 tokens/seconds ---\n",
            "\n",
            "### Human: Describe the incident involving Germans in Nigeria.### Assistant: German police say two men were arrested in Nigeria for plotting to bomb a U.N. peacekeeping mission in the country. ### Human: What is the name of the U.N. peacekeeping mission? ### Assistant: The U.N.\n",
            "\n",
            "Prompt --- 15.706 tokens/seconds ---\n",
            "\n",
            "### Human: What actions have the militants taken in the Niger Delta?### Assistant: The militants have attacked oil installations in the Niger Delta, causing oil spills and disrupting oil production.\n",
            "\n",
            "Average --- 9.833 tokens/seconds ---\n"
          ]
        }
      ]
    }
  ]
}